import os
import feedparser
import requests
import logging
import time
from datetime import datetime, timedelta
from dotenv import load_dotenv

# ‡πÇ‡∏´‡∏•‡∏î environment variables
load_dotenv()
WEBHOOK_URL = os.getenv("DISCORD_WEBHOOK_URL")

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ Webhook URL ‡∏ñ‡∏π‡∏Å‡∏ï‡∏±‡πâ‡∏á‡πÑ‡∏ß‡πâ
if not WEBHOOK_URL:
    raise ValueError("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö DISCORD_WEBHOOK_URL ‡πÉ‡∏ô .env")

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# RSS feeds ‡∏´‡∏•‡∏≤‡∏¢‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πà‡∏≤‡∏ß
RSS_FEEDS = [
    # ‡∏™‡∏≥‡∏ô‡∏±‡∏Å‡∏Ç‡πà‡∏≤‡∏ß‡πÉ‡∏´‡∏ç‡πà
    "https://www.thairath.co.th/rss/news",
    "https://www.dailynews.co.th/rss/feed/dn/feed.xml",
    "https://www.khaosod.co.th/rss.xml",
    "https://www.matichon.co.th/feed",
    "https://www.naewna.com/rss",
    "https://news.sanook.com/rss/",
    "https://www.prachachat.net/news-rss",
    "https://workpointnews.com/rss",
    "https://www.bangkokpost.com/rss/",
    "https://doh.go.th/rss/newsum",
    "https://www.nationthailand.com/rss",
    "https://rss.app/feeds/AZuuiVkf1deAllDc.xml",
    "https://www.tmd.go.th/api/xml/region-daily-forecast?regionid=7",
    
    # Google News
    # "https://news.google.com/rss?hl=th&gl=TH&ceid=TH:th", Google News ‡∏Å‡∏ß‡πâ‡∏≤‡∏á‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ
    "https://news.google.com/rss/search?q=%E0%B8%96%E0%B8%99%E0%B8%99%E0%B8%9E%E0%B8%A3%E0%B8%B0%E0%B8%A3%E0%B8%B2%E0%B8%A1?2&hl=th&gl=TH&ceid=TH:th",
    "https://news.google.com/rss/search?q=%E0%B8%AD%E0%B8%A1%E0%B8%A3%E0%B8%B4%E0%B8%99%E0%B8%97%E0%B8%A3%E0%B9%8C%E0%B8%97%E0%B8%B5%E0%B8%A7%E0%B8%B5&hl=th&gl=TH&ceid=TH:th", #‡∏≠‡∏°‡∏£‡∏¥‡∏ô‡∏ó‡∏£‡πå‡∏ó‡∏µ‡∏ß‡∏µ 
    "https://news.google.com/rss/search?q=%E0%B8%88%E0%B8%A3%E0%B8%B2%E0%B8%88%E0%B8%A3+%E0%B8%9E%E0%B8%A3%E0%B8%B0%E0%B8%A3%E0%B8%B2%E0%B8%A1?2&hl=th&gl=TH&ceid=TH:th", #‡∏à‡∏£‡∏≤‡∏à‡∏£+‡∏û‡∏£‡∏∞‡∏£‡∏≤‡∏° 2
    "https://news.google.com/rss/search?q=js100+%E0%B8%9E%E0%B8%A3%E0%B8%B0%E0%B8%A3%E0%B8%B2%E0%B8%A1?2&hl=th&gl=TH&ceid=TH:th", #js100+‡∏û‡∏£‡∏∞‡∏£‡∏≤‡∏° 2
    "https://news.google.com/rss/search?q=%E0%B8%AD%E0%B8%B8%E0%B8%9A%E0%B8%B1%E0%B8%95%E0%B8%B4%E0%B9%80%E0%B8%AB%E0%B8%95%E0%B8%B8+%E0%B8%9E%E0%B8%A3%E0%B8%B0%E0%B8%A3%E0%B8%B2%E0%B8%A1?2&hl=th&gl=TH&ceid=TH:th", #‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡πÄ‡∏´‡∏ï‡∏∏+‡∏û‡∏£‡∏∞‡∏£‡∏≤‡∏° 2
    "https://news.google.com/rss/search?q=%E0%B8%AD%E0%B8%B8%E0%B8%9A%E0%B8%B1%E0%B8%95%E0%B8%B4%E0%B9%80%E0%B8%AB%E0%B8%95%E0%B8%B8%E0%B8%9E%E0%B8%A3%E0%B8%B0%E0%B8%A3%E0%B8%B2%E0%B8%A1?2&hl=th&gl=TH&ceid=TH:th", #‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡πÄ‡∏´‡∏ï‡∏∏‡∏û‡∏£‡∏∞‡∏£‡∏≤‡∏° 2
    "https://news.google.com/rss/search?q=%E0%B8%99%E0%B9%89%E0%B8%B3%E0%B8%97%E0%B9%88%E0%B8%A7%E0%B8%A1+%E0%B8%9E%E0%B8%A3%E0%B8%B0%E0%B8%A3%E0%B8%B2%E0%B8%A1?2&hl=th&gl=TH&ceid=TH:th", #‡∏ô‡πâ‡∏≥‡∏ó‡πà‡∏ß‡∏°+‡∏û‡∏£‡∏∞‡∏£‡∏≤‡∏° 2


   
]

# ‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤
# KEYWORDS = ["‡∏û‡∏£‡∏∞‡∏£‡∏≤‡∏° 2", "‡∏û‡∏£‡∏∞‡∏£‡∏≤‡∏° 2 ‡∏ô‡πâ‡∏≥‡∏ó‡πà‡∏ß‡∏°", "‡∏û‡∏£‡∏∞‡∏£‡∏≤‡∏° 2 ‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡πÄ‡∏´‡∏ï‡∏∏", "‡∏ô‡πâ‡∏≥‡∏ó‡πà‡∏ß‡∏° ‡∏û‡∏£‡∏∞‡∏£‡∏≤‡∏° 2", "‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡πÄ‡∏´‡∏ï‡∏∏ ‡∏û‡∏£‡∏∞‡∏£‡∏≤‡∏° 2", "‡∏ñ‡∏ô‡∏ô‡∏û‡∏£‡∏∞‡∏£‡∏≤‡∏° 2"]
KEYWORDS = ["‡∏û‡∏£‡∏∞‡∏£‡∏≤‡∏° 2", "‡∏ñ‡∏ô‡∏ô‡∏û‡∏£‡∏∞‡∏£‡∏≤‡∏° 2", "‡∏ô‡πâ‡∏≥‡∏ó‡πà‡∏ß‡∏°", "‡∏ù‡∏ô‡∏ï‡∏Å"]

# ‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏Å‡πá‡∏ö‡∏•‡∏¥‡∏á‡∏Å‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡πÅ‡∏à‡πâ‡∏á‡πÅ‡∏•‡πâ‡∏ß
SEEN_LINKS_FILE = "seen_links.txt"


def load_seen_links():
    if not os.path.exists(SEEN_LINKS_FILE):
        return set()
    with open(SEEN_LINKS_FILE, "r", encoding="utf-8") as file:
        return set(line.strip() for line in file.readlines())


def save_seen_links(seen_links):
    MAX_LINKS = 1000  # ‡∏õ‡∏£‡∏±‡∏ö‡πÑ‡∏î‡πâ‡∏ï‡∏≤‡∏°‡∏Ç‡∏ô‡∏≤‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°
    trimmed_links = list(seen_links)[-MAX_LINKS:]
    with open(SEEN_LINKS_FILE, "w", encoding="utf-8") as file:
        file.write("\n".join(trimmed_links))


def send_discord_notification(title, link):
    # message = f"üõ£Ô∏è ‡∏û‡∏ö‡∏Ç‡πà‡∏≤‡∏ß‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ñ‡∏ô‡∏ô‡∏û‡∏£‡∏∞‡∏£‡∏≤‡∏° 2:\n**{title}**\n{link}"
    # try:
    #     response = requests.post(WEBHOOK_URL, json={"content": message})
    #     response.raise_for_status()
    #     logging.info(f"‚úÖ ‡∏™‡πà‡∏á‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡πÅ‡∏•‡πâ‡∏ß: {title}")
    # except requests.RequestException as e:
    #     logging.error(f"‚ùå ‡∏™‡πà‡∏á webhook ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {e}")
    
    embed = {
        "title": title,
        "url": link,
        "color": 0x00b0f4,
        "description": f"‡∏û‡∏ö‡∏Ç‡πà‡∏≤‡∏ß‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ñ‡∏ô‡∏ô‡∏û‡∏£‡∏∞‡∏£‡∏≤‡∏° 2",
        "footer": {"text": "‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡∏à‡∏≤‡∏Å‡∏£‡∏∞‡∏ö‡∏ö"},
        "timestamp": datetime.utcnow().isoformat()
    }
    payload = {"embeds": [embed]}
    
    try:
        response = requests.post(WEBHOOK_URL, json=payload)
        response.raise_for_status()
        logging.info(f"‚úÖ ‡∏™‡πà‡∏á‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡πÅ‡∏•‡πâ‡∏ß: {title}")
    except requests.RequestException as e:
        logging.error(f"‚ùå ‡∏™‡πà‡∏á webhook ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {e}")


def main():
    seen_links = load_seen_links()
    updated_links = set()

    cutoff_time = datetime.utcnow() - timedelta(hours=24)  # ‚úÖ ‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á

    for url in RSS_FEEDS:
        try:
            feed = feedparser.parse(url)
            for entry in feed.entries:
                title = entry.title
                description = entry.get("description", "")
                content = f"{title} {description}".lower()
                entry_link = entry.link

                # ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡∏±‡∏ô‡πÄ‡∏ß‡∏•‡∏≤‡∏Ç‡πà‡∏≤‡∏ß
                published = entry.get("published_parsed") or entry.get("updated_parsed")
                if published:
                    published_dt = datetime.fromtimestamp(time.mktime(published))
                    if published_dt < cutoff_time:
                        logging.debug(f"‚è±Ô∏è ‡∏Ç‡πâ‡∏≤‡∏°‡∏Ç‡πà‡∏≤‡∏ß‡πÄ‡∏Å‡πà‡∏≤: {title} ({published_dt.isoformat()})")
                        continue

                if entry_link in seen_links:
                    continue

                if any(keyword.lower() in content for keyword in KEYWORDS):
                    send_discord_notification(title, entry_link)
                    updated_links.add(entry_link)

        except Exception as e:
            logging.error(f"‚ö†Ô∏è ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏Å‡∏±‡∏ö RSS feed: {url} - {e}")

    # ‡∏£‡∏ß‡∏°‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏¥‡∏á‡∏Å‡πå‡πÉ‡∏´‡∏°‡πà
    if updated_links:
        seen_links.update(updated_links)
        save_seen_links(seen_links)
        logging.info(f"üìù ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏¥‡∏á‡∏Å‡πå‡πÉ‡∏´‡∏°‡πà‡∏à‡∏≥‡∏ô‡∏ß‡∏ô {len(updated_links)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÅ‡∏•‡πâ‡∏ß")
    else:
        logging.info("üì≠ ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πà‡∏≤‡∏ß‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á")


if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        logging.exception(f"‚ÄºÔ∏è ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô main(): {e}")
